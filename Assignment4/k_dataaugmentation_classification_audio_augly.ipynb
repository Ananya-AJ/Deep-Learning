{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpCUK51eKEXg3Sz7xXMFD9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananya-AJ/Deep-Learning/blob/main/Assignment4/k_dataaugmentation_classification_audio_augly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install augly"
      ],
      "metadata": {
        "id": "01BDIRwt91mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu librosa numpy matplotlib augly\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import augly.audio as audaugs\n",
        "from tensorflow import keras\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "ESP8muMUnqj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz"
      ],
      "metadata": {
        "id": "Rq42uViAnrx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf speech_commands_v0.02.tar.gz"
      ],
      "metadata": {
        "id": "VlI429cOoc4H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "data_dir = 'speech_commands_v0.02'\n",
        "words = ['dog', 'cat']\n",
        "num_files_per_label = 10\n",
        "\n",
        "# Create a list of all file paths and corresponding labels\n",
        "file_paths = []\n",
        "labels = []\n",
        "for word in words:\n",
        "    word_dir = os.path.join(word)\n",
        "    filenames = os.listdir(word_dir)\n",
        "    random.shuffle(filenames)  # Shuffle filenames within each label\n",
        "    filenames = filenames[:num_files_per_label]  # Choose first num_files_per_label filenames\n",
        "    for filename in filenames:\n",
        "        file_paths.append(os.path.join(word_dir, filename))\n",
        "        labels.append(word)\n",
        "\n",
        "# Shuffle the file paths and labels in unison\n",
        "zipped = list(zip(file_paths, labels))\n",
        "random.shuffle(zipped)\n",
        "file_paths, labels = zip(*zipped)"
      ],
      "metadata": {
        "id": "sl10gMr4n_Ie"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to extract features from audio files\n",
        "def extract_features(file_path):\n",
        "    # load audio file\n",
        "    audio_file, sr = librosa.load(file_path)\n",
        "    # extract Mel-frequency cepstral coefficients (MFCCs) from the audio signal\n",
        "    mfccs = librosa.feature.mfcc(y=audio_file, sr=sr, n_mfcc=40)\n",
        "    # pad or truncate the sequence to be of length 174\n",
        "    pad_width = 174 - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    return mfccs\n"
      ],
      "metadata": {
        "id": "kKPtzFKmt6sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "cat_folder = './cat'\n",
        "dog_folder = './dog'\n",
        "\n",
        "cat_data = []\n",
        "dog_data = []\n",
        "\n",
        "# select first 10 files from cat folder\n",
        "for i, file_name in enumerate(os.listdir(cat_folder)):\n",
        "    if i == 10:\n",
        "        break\n",
        "    file_path = os.path.join(cat_folder, file_name)\n",
        "    cat_data.append(extract_features(file_path))\n",
        "\n",
        "# select first 10 files from dog folder\n",
        "for i, file_name in enumerate(os.listdir(dog_folder)):\n",
        "    if i == 10:\n",
        "        break\n",
        "    file_path = os.path.join(dog_folder, file_name)\n",
        "    dog_data.append(extract_features(file_path))\n",
        "\n",
        "cat_data = np.array(cat_data)\n",
        "dog_data = np.array(dog_data)\n",
        "\n",
        "# create labels for the data\n",
        "cat_labels = np.zeros(len(cat_data))\n",
        "dog_labels = np.ones(len(dog_data))\n",
        "\n",
        "# concatenate the data and labels\n",
        "X = np.concatenate((cat_data, dog_data), axis=0)\n",
        "y = np.concatenate((cat_labels, dog_labels), axis=0)\n",
        "\n",
        "# reshape data for input to neural network\n",
        "X = X.reshape(X.shape[0], 40, 174, 1)\n"
      ],
      "metadata": {
        "id": "utPxBCf0t8gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "qkpZ6AdewC0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# build the neural network\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(40, 174, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "KgZMfUoAwJcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "DrFLxVApwnmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRdpyFkYwsF9",
        "outputId": "cd399d5b-266c-4119-848f-d6e939c75ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step - loss: 1.5879 - accuracy: 0.5000\n",
            "Test accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With audio augmentation using augly"
      ],
      "metadata": {
        "id": "uKx3kZVrw-8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install augly[audio]"
      ],
      "metadata": {
        "id": "tFQTx2R_0SH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply pitch shift augmentation on the cat and dog audio files at sample rate of 16000"
      ],
      "metadata": {
        "id": "dRZGOmBd8yyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import augly.audio as audaugs\n",
        "\n",
        "import librosa\n",
        "\n",
        "def augment(file_path, sample_rate=16000):\n",
        "    audio_data, _ = librosa.load(file_path, sr=sample_rate)\n",
        "    aug_audio_data, sr = audaugs.pitch_shift(audio_data, n_steps=10)\n",
        "    return aug_audio_data\n",
        "\n",
        "# Load the audio files\n",
        "cat_files = [os.path.join(\"./cat\", f) for f in os.listdir(\"./cat\") if f.endswith(\".wav\")]\n",
        "dog_files = [os.path.join(\"./dog\", f) for f in os.listdir(\"./dog\") if f.endswith(\".wav\")]\n",
        "\n",
        "# Augment the audio files\n",
        "cat_files_aug = [augment(f, sample_rate=16000) for f in cat_files]\n",
        "dog_files_aug = [augment(f, sample_rate=16000) for f in dog_files]"
      ],
      "metadata": {
        "id": "t56Kia7O6Q20"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dog_files_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW0yhW6Zs4VE",
        "outputId": "f86c0da0-54ce-4c7c-e5d3-900f2629d64e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract spectrograms for the augmented audio files. spectrograms help capture both temporal and frequency information in the audio signal(raw audio) and returns a numpy ndarray"
      ],
      "metadata": {
        "id": "7PHtTdJ6860h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mel_spectrograms(audio_data, sr=16000, n_fft=2048, hop_length=512, n_mels=128):\n",
        "    mel_spectrograms = []\n",
        "    for audio in audio_data:\n",
        "        # Extract Mel spectrogram\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "        # Convert to decibels\n",
        "        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "        mel_spectrograms.append(log_mel_spectrogram)\n",
        "    return mel_spectrograms\n"
      ],
      "metadata": {
        "id": "4UsdtLyxkute"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_files_aug_mel = extract_mel_spectrograms(cat_files_aug)\n",
        "dog_files_aug_mel = extract_mel_spectrograms(dog_files_aug)"
      ],
      "metadata": {
        "id": "bLMJtLX3pp69"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping the spectrograms by adding 4th dimension"
      ],
      "metadata": {
        "id": "zv6hoyj49Urt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_time_steps = max([m.shape[1] for m in cat_files_aug_mel + dog_files_aug_mel])\n",
        "\n",
        "# Pad or truncate each Mel spectrogram to have the same number of time steps\n",
        "cat_files_aug_mel = np.array([np.pad(m, ((0, 0), (0, max_time_steps - m.shape[1])), mode='constant') for m in cat_files_aug_mel])\n",
        "dog_files_aug_mel = np.array([np.pad(m, ((0, 0), (0, max_time_steps - m.shape[1])), mode='constant') for m in dog_files_aug_mel])\n",
        "\n",
        "# Combine cat and dog Mel spectrograms and create labels\n",
        "X = np.concatenate((cat_files_aug_mel, dog_files_aug_mel), axis=0)\n",
        "y = np.concatenate((np.zeros(len(cat_files_aug_mel)), np.ones(len(dog_files_aug_mel))), axis=0)\n"
      ],
      "metadata": {
        "id": "7f7BuboR3rqw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Reshape the data to include an extra dimension\n",
        "X = np.expand_dims(X, axis=-1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print('Test accuracy:', test_acc)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tcD6bwy2ssF",
        "outputId": "fb294ea6-bbed-48cb-d2e0-ca603b2c0fd0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "104/104 [==============================] - 26s 239ms/step - loss: 0.8969 - accuracy: 0.7622 - val_loss: 0.1997 - val_accuracy: 0.9351\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 34s 325ms/step - loss: 0.1657 - accuracy: 0.9342 - val_loss: 0.2395 - val_accuracy: 0.9087\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 38s 362ms/step - loss: 0.1316 - accuracy: 0.9462 - val_loss: 0.1368 - val_accuracy: 0.9459\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 26s 249ms/step - loss: 0.1006 - accuracy: 0.9624 - val_loss: 0.1260 - val_accuracy: 0.9471\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 27s 259ms/step - loss: 0.0884 - accuracy: 0.9684 - val_loss: 0.1086 - val_accuracy: 0.9531\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 34s 324ms/step - loss: 0.0912 - accuracy: 0.9678 - val_loss: 0.1364 - val_accuracy: 0.9423\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 34s 331ms/step - loss: 0.0814 - accuracy: 0.9687 - val_loss: 0.1074 - val_accuracy: 0.9615\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 23s 220ms/step - loss: 0.0710 - accuracy: 0.9729 - val_loss: 0.1888 - val_accuracy: 0.9303\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 33s 320ms/step - loss: 0.0714 - accuracy: 0.9708 - val_loss: 0.1114 - val_accuracy: 0.9591\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.0565 - accuracy: 0.9784 - val_loss: 0.1505 - val_accuracy: 0.9423\n",
            "26/26 [==============================] - 1s 50ms/step - loss: 0.1505 - accuracy: 0.9423\n",
            "Test accuracy: 0.942307710647583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that accuracy drastically increased from 50% to 94% after augmenting the audio files using pitchshift. The loss reduced incredibly too"
      ],
      "metadata": {
        "id": "ele8tXcx9nEh"
      }
    }
  ]
}