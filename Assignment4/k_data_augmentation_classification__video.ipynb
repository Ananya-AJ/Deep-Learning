{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKgX1VI158ZgyFQOZV+ktg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananya-AJ/Deep-Learning/blob/main/Assignment4/k_data_augmentation_classification__video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: restart runtime after this import before running the augmentations\n",
        "!pip install -U augly[video]\n",
        "!sudo apt-get install python3-magic"
      ],
      "metadata": {
        "id": "-kNnX1NU_ybO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
        "!unrar x hmdb51_org.rar"
      ],
      "metadata": {
        "id": "BmEGRScXu1bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x shoot_gun.rar"
      ],
      "metadata": {
        "id": "LeVDko4KwK2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x brush_hair.rar"
      ],
      "metadata": {
        "id": "QjX2X6tcxTq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless\n",
        "!pip install av"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojrykB6CwNyy",
        "outputId": "eae89c41-6105-448c-8879-eee07aa40111"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.9/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from opencv-python-headless) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting av\n",
            "  Downloading av-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-10.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "data_dir_1 = './brush_hair'\n",
        "data_dir_2 = './shoot_gun'\n",
        "img_size = 64\n",
        "\n",
        "# Read frames from videos in the first directory\n",
        "data_1 = []\n",
        "for i, filename in enumerate(os.listdir(data_dir_1)):\n",
        "    if i == 5:\n",
        "        break\n",
        "    video_path = os.path.join(data_dir_1, filename)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, (img_size, img_size))\n",
        "        data_1.append(frame)\n",
        "    cap.release()\n",
        "\n",
        "# Read frames from videos in the second directory\n",
        "data_2 = []\n",
        "for i, filename in enumerate(os.listdir(data_dir_2)):\n",
        "    if i == 5:\n",
        "        break\n",
        "    video_path = os.path.join(data_dir_2, filename)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, (img_size, img_size))\n",
        "        data_2.append(frame)\n",
        "    cap.release()\n",
        "\n",
        "# Create labels for the data\n",
        "labels_1 = np.zeros(len(data_1))\n",
        "labels_2 = np.ones(len(data_2))\n",
        "\n",
        "# Combine the data and labels\n",
        "data = np.array(data_1 + data_2)\n",
        "labels = np.concatenate((labels_1, labels_2))\n",
        "\n",
        "# Shuffle the data and labels\n",
        "idx = np.random.permutation(len(data))\n",
        "data = data[idx]\n",
        "labels = labels[idx]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "split = int(0.8 * len(data))\n",
        "x_train = data[:split]\n",
        "y_train = labels[:split]\n",
        "x_test = data[split:]\n",
        "y_test = labels[split:]\n"
      ],
      "metadata": {
        "id": "jqnDaK0nXTKO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1weVIERXmXI",
        "outputId": "6973ab95-2bad-446e-b572-3407986dd6d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 12s 21ms/step - loss: 2.5785 - accuracy: 0.9123 - val_loss: 3.3419e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.3728e-05 - accuracy: 1.0000 - val_loss: 1.1320e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 4.6332e-07 - accuracy: 1.0000 - val_loss: 4.2393e-07 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.2619e-07 - accuracy: 1.0000 - val_loss: 2.6564e-07 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 1.6372e-07 - accuracy: 1.0000 - val_loss: 2.0874e-07 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.3379e-07 - accuracy: 1.0000 - val_loss: 1.8221e-07 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 1.1651e-07 - accuracy: 1.0000 - val_loss: 1.6148e-07 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.0506e-07 - accuracy: 1.0000 - val_loss: 1.4692e-07 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 9.5193e-08 - accuracy: 1.0000 - val_loss: 1.3601e-07 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 8.7714e-08 - accuracy: 1.0000 - val_loss: 1.2569e-07 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6030242730>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy is low as we are only using 5 videos of each class to train, this experiment is just to check if anything changes from pre data augmentation to post data augmentation. The colab crashes with more number of videos"
      ],
      "metadata": {
        "id": "IyTpvqPIXxRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation using augly video, adding noise and blurring the videos"
      ],
      "metadata": {
        "id": "4X91ewZkX_7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import augly.video as vidaugs\n",
        "\n",
        "# Define the augmentations to be applied to the videos\n",
        "aug = vidaugs.Compose([\n",
        "    vidaugs.AddNoise(),\n",
        "    vidaugs.Blur(sigma=5.0),\n",
        "    vidaugs.OverlayDots(),\n",
        "])\n",
        "\n",
        "# Define the paths to the video files\n",
        "videos_path = \"./\"\n",
        "shoot_gun_path = os.path.join(videos_path, \"shoot_gun\")\n",
        "brush_hair_path = os.path.join(videos_path, \"brush_hair\")\n",
        "\n",
        "# Define the size of the video frames\n",
        "img_size = 224\n",
        "\n",
        "# Define the data lists\n",
        "data_1 = []\n",
        "labels_1 = []\n",
        "data_2 = []\n",
        "labels_2 = []\n",
        "\n",
        "# Read the first 5 videos from the shoot_gun folder\n",
        "for i, filename in enumerate(os.listdir(shoot_gun_path)[:5]):\n",
        "    if filename.endswith(\".avi\"):\n",
        "        filepath = os.path.join(shoot_gun_path, filename)\n",
        "        cap = cv2.VideoCapture(filepath)\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = cv2.resize(frame, (img_size, img_size))\n",
        "            writer = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (img_size, img_size), True)\n",
        "            writer.write(frame)\n",
        "            writer.release()\n",
        "            aug_video = cv2.VideoCapture(\"output.avi\")\n",
        "            aug_frames = []\n",
        "            while aug_video.isOpened():\n",
        "                ret, frame = aug_video.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                aug_frames.append(frame)\n",
        "            aug_video.release()\n",
        "            os.remove(\"output.avi\")\n",
        "            aug_data = np.array(aug_frames)\n",
        "            data_1.append(aug_data)\n",
        "        cap.release()\n",
        "\n",
        "# Read the first 5 videos from the brush_hair folder\n",
        "for i, filename in enumerate(os.listdir(brush_hair_path)[:5]):\n",
        "    if filename.endswith(\".avi\"):\n",
        "        filepath = os.path.join(brush_hair_path, filename)\n",
        "        cap = cv2.VideoCapture(filepath)\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = cv2.resize(frame, (img_size, img_size))\n",
        "            writer = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (img_size, img_size), True)\n",
        "            writer.write(frame)\n",
        "            writer.release()\n",
        "            aug_video = cv2.VideoCapture(\"output.avi\")\n",
        "            aug_frames = []\n",
        "            while aug_video.isOpened():\n",
        "                ret, frame = aug_video.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                aug_frames.append(frame)\n",
        "            aug_video.release()\n",
        "            os.remove(\"output.avi\")\n",
        "            aug_data = np.array(aug_frames)\n",
        "            data_2.append(aug_data)\n",
        "        cap.release()\n",
        "\n",
        "print(len(data_1))\n",
        "print(len(data_2))\n",
        "\n",
        "# Convert the data lists to numpy arrays\n",
        "data_1 = np.concatenate(data_1, axis=0)\n",
        "data_2 = np.concatenate(data_2, axis=0)\n",
        "\n",
        "\n",
        "# Create the labels for the data\n",
        "labels_1 = np.zeros((data_1.shape[0],))\n",
        "labels_2 = np.ones((data_2.shape[0],))\n",
        "\n",
        "# Merge the data and labels\n",
        "X = np.concatenate((data_1, data_2))\n",
        "y = np.concatenate((labels_1, labels_2))\n",
        "\n",
        "# Shuffle the data and labels\n",
        "p = np.random.permutation(X.shape[0])\n",
        "X = X[p]\n",
        "y = y[p]\n",
        "\n",
        "# Split the data and labels into training and testing sets\n",
        "split = int(0.8 * X.shape[0])\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYC-dcgif97e",
        "outputId": "fb826977-e294-47c3-abdc-d03e069dc07c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "463\n",
            "1091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsyfxH-Xjy_7",
        "outputId": "87b6b929-026e-4fad-f211-b8a62e3e3256"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1243, 224, 224, 3)\n",
            "(311, 224, 224, 3)\n",
            "(1243,)\n",
            "(311,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# img_size = 224\n",
        "\n",
        "# # Reshape the data to be used in the 3D CNN\n",
        "# X_train = X_train.reshape((-1, 16, img_size, img_size, 3))\n",
        "# y_train = y_train.reshape((-1, 16, img_size, img_size, 3))\n"
      ],
      "metadata": {
        "id": "sXbkJ0e8hNcx"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Define the CNN model architecture\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiypeRksjP3e",
        "outputId": "1d74affa-b38a-49dd-c062-10facff7ef3a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 7s 83ms/step - loss: 16.3066 - accuracy: 0.9276 - val_loss: 3.7606e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 2s 48ms/step - loss: 4.4585e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9968\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 2s 48ms/step - loss: 3.3629e-04 - accuracy: 1.0000 - val_loss: 4.6631e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 2s 49ms/step - loss: 8.6647e-05 - accuracy: 1.0000 - val_loss: 1.0848e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 2s 49ms/step - loss: 2.3000e-06 - accuracy: 1.0000 - val_loss: 3.2160e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 2s 48ms/step - loss: 2.8489e-05 - accuracy: 1.0000 - val_loss: 3.9091e-07 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 2s 48ms/step - loss: 1.0323e-06 - accuracy: 1.0000 - val_loss: 2.4784e-08 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 2s 48ms/step - loss: 1.6959e-06 - accuracy: 1.0000 - val_loss: 1.8324e-08 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 2s 48ms/step - loss: 1.8967e-07 - accuracy: 1.0000 - val_loss: 1.4633e-08 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 2s 48ms/step - loss: 4.2767e-06 - accuracy: 1.0000 - val_loss: 1.5510e-08 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5ebe23e5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ane56dcebaz",
        "outputId": "8f34e3f6-ee42-4bd8-c7f1-57698e4fb47a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 17ms/step - loss: 1.5510e-08 - accuracy: 1.0000\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "val accuracy doesnt change as we have only 5 videos for each class , however the loss reduces considerabley from 8.7 to 4.2. More than 5 videos, colab crashes"
      ],
      "metadata": {
        "id": "160AdG9jm-7t"
      }
    }
  ]
}