{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzSK5dWfJH5yz2qi+2zShr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananya-AJ/Deep-Learning/blob/main/codelab_DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MNSIT Digits classification"
      ],
      "metadata": {
        "id": "33isdt3NtJLi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PM2fQqCRsAyF"
      },
      "outputs": [],
      "source": [
        "#Datasets path\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "training_images_file   = 'gs://mnist-public/train-images-idx3-ubyte'\n",
        "training_labels_file   = 'gs://mnist-public/train-labels-idx1-ubyte'\n",
        "validation_images_file = 'gs://mnist-public/t10k-images-idx3-ubyte'\n",
        "validation_labels_file = 'gs://mnist-public/t10k-labels-idx1-ubyte'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import os, re, math, json, shutil, pprint\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import IPython.display as display\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dTxWD9HtIUV",
        "outputId": "bc920fde-8aa3-4867-ead6-79289c8fc182"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parse files and prepare training and validation datasets\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def read_label(tf_bytestring):\n",
        "    label = tf.io.decode_raw(tf_bytestring, tf.uint8)\n",
        "    label = tf.reshape(label, [])\n",
        "    label = tf.one_hot(label, 10)\n",
        "    return label\n",
        "  \n",
        "def read_image(tf_bytestring):\n",
        "    image = tf.io.decode_raw(tf_bytestring, tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)/256.0\n",
        "    image = tf.reshape(image, [28*28])\n",
        "    return image\n",
        "  \n",
        "def load_dataset(image_file, label_file):\n",
        "    imagedataset = tf.data.FixedLengthRecordDataset(image_file, 28*28, header_bytes=16)\n",
        "    imagedataset = imagedataset.map(read_image, num_parallel_calls=16)\n",
        "    labelsdataset = tf.data.FixedLengthRecordDataset(label_file, 1, header_bytes=8)\n",
        "    labelsdataset = labelsdataset.map(read_label, num_parallel_calls=16)\n",
        "    dataset = tf.data.Dataset.zip((imagedataset, labelsdataset))\n",
        "    return dataset \n",
        "  \n",
        "def get_training_dataset(image_file, label_file, batch_size):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache()  # this small dataset can be entirely cached in RAM, for TPU this is important to get good performance from such a small dataset\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat() # Mandatory for Keras for now\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True) # drop_remainder is important on TPU, batch size must be fixed\n",
        "    dataset = dataset.prefetch(AUTO)  # fetch next batches while training on the current one (-1: autotune prefetch buffer size)\n",
        "    return dataset\n",
        "  \n",
        "def get_validation_dataset(image_file, label_file):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache() # this small dataset can be entirely cached in RAM, for TPU this is important to get good performance from such a small dataset\n",
        "    dataset = dataset.batch(10000, drop_remainder=True) # 10000 items in eval dataset, all in one batch\n",
        "    dataset = dataset.repeat() # Mandatory for Keras for now\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "J5VpMgJstUMd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the datasets\n",
        "training_dataset = get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
        "validation_dataset = get_validation_dataset(validation_images_file, validation_labels_file)"
      ],
      "metadata": {
        "id": "mfQH6YUst060"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Single dense layer keras model\n",
        "model = tf.keras.Sequential(\n",
        "  [\n",
        "      tf.keras.layers.Input(shape=(28*28,)),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print model layers\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2IN2BhCt-4g",
        "outputId": "4fff64d3-96d3-4d20-b290-54ef3b4ff947"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model fitting\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrqAPqCfvFKI",
        "outputId": "a3c4afed-5d77-45fe-c3a4-449d5acaaae1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "468/468 [==============================] - 12s 14ms/step - loss: 1.2991 - accuracy: 0.6793 - val_loss: 0.8254 - val_accuracy: 0.8275\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.7233 - accuracy: 0.8358 - val_loss: 0.6134 - val_accuracy: 0.8600\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.5903 - accuracy: 0.8578 - val_loss: 0.5289 - val_accuracy: 0.8743\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.5281 - accuracy: 0.8681 - val_loss: 0.4821 - val_accuracy: 0.8818\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.4887 - accuracy: 0.8756 - val_loss: 0.4516 - val_accuracy: 0.8866\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.4633 - accuracy: 0.8799 - val_loss: 0.4301 - val_accuracy: 0.8899\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.4426 - accuracy: 0.8836 - val_loss: 0.4135 - val_accuracy: 0.8922\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.4294 - accuracy: 0.8861 - val_loss: 0.4008 - val_accuracy: 0.8937\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.4162 - accuracy: 0.8887 - val_loss: 0.3900 - val_accuracy: 0.8957\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.4070 - accuracy: 0.8904 - val_loss: 0.3814 - val_accuracy: 0.8975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict validation set\n",
        "probabilities = model.predict(validation_dataset, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "print(probabilities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqoQIgPsvZFI",
        "outputId": "4472c5f4-ee02-4a51-ea71-c40ba194fde9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "[[4.6183707e-04 5.3596132e-06 4.1749989e-04 ... 9.9190181e-01\n",
            "  3.0035275e-04 5.4066749e-03]\n",
            " [2.7850334e-02 7.9880044e-04 7.8790081e-01 ... 5.6100776e-06\n",
            "  1.5689865e-02 2.2484439e-05]\n",
            " [6.1581779e-04 9.3526483e-01 1.8712290e-02 ... 6.4876601e-03\n",
            "  1.4741043e-02 2.7840391e-03]\n",
            " ...\n",
            " [2.6643567e-05 1.0657802e-04 3.1363167e-04 ... 1.2684549e-02\n",
            "  2.5582161e-02 7.4805930e-02]\n",
            " [1.4677294e-02 3.1935733e-02 4.9440577e-03 ... 7.2448119e-03\n",
            "  4.3836027e-01 4.1911625e-03]\n",
            " [1.2302076e-03 2.4116520e-07 2.4626211e-03 ... 8.9493057e-07\n",
            "  3.0378407e-05 6.8762697e-06]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adding more layers"
      ],
      "metadata": {
        "id": "o9qoDMONwPx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(\n",
        "  [\n",
        "      tf.keras.layers.Input(shape=(28*28,)),\n",
        "      tf.keras.layers.Dense(200, activation='sigmoid'),\n",
        "      tf.keras.layers.Dense(60, activation='sigmoid'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])"
      ],
      "metadata": {
        "id": "Tvlrs5lKwHF7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print model layers\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XThQJl_twjnb",
        "outputId": "8b4dc510-4c55-4c9a-d52b-2a6b947ece49"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 200)               157000    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 60)                12060     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                610       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,670\n",
            "Trainable params: 169,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train and validate\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug_z-rtIwoIf",
        "outputId": "13303939-f824-4251-c932-8fda81013d15"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.7199 - accuracy: 0.8327 - val_loss: 0.3001 - val_accuracy: 0.9188\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.2547 - accuracy: 0.9285 - val_loss: 0.2135 - val_accuracy: 0.9375\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.1893 - accuracy: 0.9452 - val_loss: 0.1672 - val_accuracy: 0.9504\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.1495 - accuracy: 0.9561 - val_loss: 0.1421 - val_accuracy: 0.9579\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.1207 - accuracy: 0.9646 - val_loss: 0.1227 - val_accuracy: 0.9636\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0988 - accuracy: 0.9711 - val_loss: 0.1047 - val_accuracy: 0.9700\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.0819 - accuracy: 0.9763 - val_loss: 0.0940 - val_accuracy: 0.9712\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0681 - accuracy: 0.9805 - val_loss: 0.0883 - val_accuracy: 0.9742\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.0572 - accuracy: 0.9837 - val_loss: 0.0801 - val_accuracy: 0.9750\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0483 - accuracy: 0.9864 - val_loss: 0.0780 - val_accuracy: 0.9769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P-9gxewqxA6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Learning rate decay"
      ],
      "metadata": {
        "id": "DAIYS0d3xJvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lr decay function\n",
        "def lr_decay(epoch):\n",
        "  return 0.01 * math.pow(0.6, epoch)\n",
        "\n",
        "# lr schedule callback\n",
        "lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)"
      ],
      "metadata": {
        "id": "aDNbbsRoxOQU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(28*28,)),\n",
        "      tf.keras.layers.Dense(200, activation='relu'),\n",
        "      tf.keras.layers.Dense(60, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "# Defining model architecture\n",
        "model_.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_.summary()\n",
        "\n",
        "# Fit model\n",
        "history = model_.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay_callback])\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOSz99_7xe9U",
        "outputId": "9f7ac387-a3e3-4336-d8e0-813c86f1a8a4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 200)               157000    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 60)                12060     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                610       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,670\n",
            "Trainable params: 169,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.2195 - accuracy: 0.9338 - val_loss: 0.1506 - val_accuracy: 0.9548 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.006.\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.0892 - accuracy: 0.9725 - val_loss: 0.1022 - val_accuracy: 0.9729 - lr: 0.0060\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0036.\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.0868 - val_accuracy: 0.9748 - lr: 0.0036\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0021599999999999996.\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.0671 - val_accuracy: 0.9802 - lr: 0.0022\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001296.\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.0676 - val_accuracy: 0.9824 - lr: 0.0013\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0007775999999999998.\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0658 - val_accuracy: 0.9824 - lr: 7.7760e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0004665599999999999.\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0664 - val_accuracy: 0.9821 - lr: 4.6656e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00027993599999999994.\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0675 - val_accuracy: 0.9825 - lr: 2.7994e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.00016796159999999993.\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0680 - val_accuracy: 0.9822 - lr: 1.6796e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00010077695999999997.\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0686 - val_accuracy: 0.9824 - lr: 1.0078e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding more layers to the network\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=12, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=6, filters=24, strides=2, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=6, filters=32, strides=2, activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_.summary()\n",
        "\n",
        "# Fit model\n",
        "history = model_.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay_callback])\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6uwwHTDxqQw",
        "outputId": "6f133aab-b172-42c1-ce83-6735f27dd52b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 200)               157000    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 60)                12060     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                610       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,670\n",
            "Trainable params: 169,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0989 - accuracy: 0.9710 - val_loss: 0.1208 - val_accuracy: 0.9677 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.006.\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0510 - accuracy: 0.9835 - val_loss: 0.1004 - val_accuracy: 0.9768 - lr: 0.0060\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0036.\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0864 - val_accuracy: 0.9804 - lr: 0.0036\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0021599999999999996.\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.0784 - val_accuracy: 0.9816 - lr: 0.0022\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001296.\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0812 - val_accuracy: 0.9828 - lr: 0.0013\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0007775999999999998.\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0840 - val_accuracy: 0.9825 - lr: 7.7760e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0004665599999999999.\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0856 - val_accuracy: 0.9829 - lr: 4.6656e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00027993599999999994.\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0862 - val_accuracy: 0.9826 - lr: 2.7994e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.00016796159999999993.\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0869 - val_accuracy: 0.9829 - lr: 1.6796e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00010077695999999997.\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0876 - val_accuracy: 0.9828 - lr: 1.0078e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convolutional Neural Network"
      ],
      "metadata": {
        "id": "a6oQtHhKyv4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(\n",
        "  [\n",
        "      tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.Conv2D(kernel_size=3, filters=12, activation='relu', padding='same'),\n",
        "      tf.keras.layers.Conv2D(kernel_size=6, filters=24, activation='relu', padding='same', strides=2),\n",
        "      tf.keras.layers.Conv2D(kernel_size=6, filters=32, activation='relu', padding='same', strides=2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(200, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print model layers\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t46kFtqyxxC",
        "outputId": "3c57e3de-d0c6-4fe4-eec5-a67181d48986"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_1 (Reshape)         (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 12)        120       \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 24)        10392     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 7, 7, 32)          27680     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 200)               313800    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                2010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 354,002\n",
            "Trainable params: 354,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "history = model_.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay_callback])\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJW3y27iy5f1",
        "outputId": "5d192e97-3b18-4bfb-9ec3-1ba32102658d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.2246 - accuracy: 0.9419 - val_loss: 0.1459 - val_accuracy: 0.9645 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.006.\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0779 - accuracy: 0.9774 - val_loss: 0.1083 - val_accuracy: 0.9737 - lr: 0.0060\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0036.\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0434 - accuracy: 0.9869 - val_loss: 0.1012 - val_accuracy: 0.9759 - lr: 0.0036\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0021599999999999996.\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.0277 - accuracy: 0.9919 - val_loss: 0.1051 - val_accuracy: 0.9755 - lr: 0.0022\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001296.\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.1011 - val_accuracy: 0.9762 - lr: 0.0013\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0007775999999999998.\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.1036 - val_accuracy: 0.9768 - lr: 7.7760e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0004665599999999999.\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.1055 - val_accuracy: 0.9765 - lr: 4.6656e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00027993599999999994.\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.1069 - val_accuracy: 0.9765 - lr: 2.7994e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.00016796159999999993.\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.1082 - val_accuracy: 0.9766 - lr: 1.6796e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00010077695999999997.\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.1087 - val_accuracy: 0.9771 - lr: 1.0078e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Batch normalisation"
      ],
      "metadata": {
        "id": "c4xxn-Mczf-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(\n",
        "  [\n",
        "      tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\n",
        "      \n",
        "      tf.keras.layers.Conv2D(kernel_size=3, filters=12, use_bias=False, padding='same'),\n",
        "      tf.keras.layers.BatchNormalization(center=True, scale=False),\n",
        "      tf.keras.layers.Activation('relu'),\n",
        "      \n",
        "      tf.keras.layers.Conv2D(kernel_size=6, filters=24, use_bias=False, padding='same', strides=2),\n",
        "      tf.keras.layers.BatchNormalization(center=True, scale=False),\n",
        "      tf.keras.layers.Activation('relu'),\n",
        "      \n",
        "      tf.keras.layers.Conv2D(kernel_size=6, filters=32, use_bias=False, padding='same', strides=2),\n",
        "      tf.keras.layers.BatchNormalization(center=True, scale=False),\n",
        "      tf.keras.layers.Activation('relu'),\n",
        "      \n",
        "      tf.keras.layers.Flatten(),\n",
        "      \n",
        "      tf.keras.layers.Dense(200, use_bias=False),\n",
        "      tf.keras.layers.BatchNormalization(center=True, scale=False),\n",
        "      tf.keras.layers.Activation('relu'),\n",
        "      \n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print model layers\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ij88phzgO_",
        "outputId": "fa9f1757-26ad-46e9-cfba-5f10186e79f8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_2 (Reshape)         (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 12)        108       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 28, 28, 12)       36        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 28, 28, 12)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 14, 24)        10368     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 14, 14, 24)       72        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 14, 14, 24)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 7, 7, 32)          27648     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 7, 7, 32)         96        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 7, 7, 32)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 200)               313600    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 200)              600       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 200)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                2010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 354,538\n",
            "Trainable params: 354,002\n",
            "Non-trainable params: 536\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}