{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananya-AJ/Deep-Learning/blob/main/Assignment5/SemanticKernel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install and import semantic kernel"
      ],
      "metadata": {
        "id": "vWmiO33wnBFU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQiqLLZsiCp6",
        "outputId": "7b08aadd-a843-413b-ee58-5f2b0fa18338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting semantic-kernel\n",
            "  Downloading semantic_kernel-0.2.3.dev0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<0.28.0,>=0.27.0\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<2.0.0,>=1.24.2\n",
            "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asyncio<4.0.0,>=3.4.3\n",
            "  Downloading asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0.0,>=23.1.0\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai<0.28.0,>=0.27.0->semantic-kernel) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai<0.28.0,>=0.27.0->semantic-kernel) (4.65.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel) (2.0.12)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: asyncio, numpy, multidict, frozenlist, async-timeout, aiofiles, yarl, aiosignal, aiohttp, openai, semantic-kernel\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.2 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 asyncio-3.4.3 frozenlist-1.3.3 multidict-6.0.4 numpy-1.24.2 openai-0.27.4 semantic-kernel-0.2.3.dev0 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade semantic-kernel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY=\"YOU_API_KEY\""
      ],
      "metadata": {
        "id": "nzVicIF_iJF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import semantic_kernel as sk\n",
        "from semantic_kernel.ai.open_ai import OpenAITextCompletion"
      ],
      "metadata": {
        "id": "DDdPMOKMifX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = sk.Kernel()"
      ],
      "metadata": {
        "id": "sMSBPiACigay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare OpenAI backend using credentials stored in the `.env` file\n",
        "api_key = OPENAI_API_KEY\n",
        "kernel.config.add_text_backend(\"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHgIAuz9ih44",
        "outputId": "90f49544-d20d-4500-e5a5-511fcae5d14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<semantic_kernel.kernel_config.KernelConfig at 0x7f8b09bb5190>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using semantic function to get the TLDR of a given summary"
      ],
      "metadata": {
        "id": "HZnCeJuCmGdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap the prompt in a function\n",
        "prompt = kernel.create_semantic_function(\"\"\"\n",
        "In some countries, red light cameras are used for either the driver or the vehicle's owner. An automated camera is connected to the triggering mechanism for the corresponding traffic light, which is programmed to photograph a vehicle and driver crossing against the light. Either the driver or the vehicle's owner (depending on the locale) are fined for the violation. In some jurisdictions, including the United States and Italy, private companies have been contracted to operate traffic-related cameras and receive a portion of the resulting revenues. In some cases, red light cameras have been abused by local governments, where vehicle operators have been fined as a result of traffic systems that have been improperly modified.[20][21] Despite the fact that cameras can reduce the number of crashes, it has been proven that at these intersections drivers tended to react quicker to an amber light change when stopping.[22][23] The consequence of this change could be a slight decline in the intersection capacity.\n",
        "\n",
        "Red light cameras in New South Wales, Australia, are activated only if a motorist enters an intersection 0.3 seconds after the light has turned red\n",
        "\n",
        "Give me the TLDR in exactly 10 words.\"\"\")\n",
        "\n",
        "# Run the prompt\n",
        "print(prompt())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FuOQs__iaEj",
        "outputId": "e2a86c61-86a2-45b8-efab-0412d46964ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Red light cameras fine drivers or owners for violations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using semantic function to explain the meaning of a given poem"
      ],
      "metadata": {
        "id": "J4YV7cSnjuSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = kernel.create_semantic_function(\"\"\"\n",
        "Explain the meaning of the poem below:\n",
        "Where the mind is without fear\n",
        "and the head is held high\n",
        "Where knowledge is free\n",
        "Where the world has not been broken\n",
        "up into fragments by narrow domestic walls;\n",
        "Where words come out from the\n",
        "depths of truth;\n",
        "Where tireless striving\n",
        "stretches its arms towards perfection;\n",
        "Where the clear stream of reason\n",
        "has not lost its way into the\n",
        "dreary desert sand of dead habit;\n",
        "Where the mind is led forward\n",
        "by thee into ever widening\n",
        "thought and action\u0002into that heaven of freedom,\n",
        "my father,\n",
        "let my country awake\n",
        "\"\"\")\n",
        "\n",
        "# Run the prompt\n",
        "print(prompt())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK8d17DJjTnn",
        "outputId": "befb0b42-a4c1-4a82-bd8e-93649fd7672c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "This poem is a call to action for the people of India to strive for a better future. The speaker is asking for a world where the mind is free from fear and oppression, where knowledge is free and accessible, and where the world is not divided by narrow walls. They ask for words to come from truth, and for tireless striving towards perfection. They ask for reason to be followed, and for the mind to be led forward into ever-widening thought and action. Finally, they ask for their country to be awakened to this vision of freedom.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setting up the semantic kernel"
      ],
      "metadata": {
        "id": "AlQ0jMwum3jU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install semantic-kernel==0.2.3.dev0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnCvgEU0kdoV",
        "outputId": "adc0f26e-3509-43b6-8ad8-e19afa3c90da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: semantic-kernel==0.2.3.dev0 in /usr/local/lib/python3.9/dist-packages (0.2.3.dev0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.2 in /usr/local/lib/python3.9/dist-packages (from semantic-kernel==0.2.3.dev0) (1.24.2)\n",
            "Requirement already satisfied: openai<0.28.0,>=0.27.0 in /usr/local/lib/python3.9/dist-packages (from semantic-kernel==0.2.3.dev0) (0.27.4)\n",
            "Requirement already satisfied: aiofiles<24.0.0,>=23.1.0 in /usr/local/lib/python3.9/dist-packages (from semantic-kernel==0.2.3.dev0) (23.1.0)\n",
            "Requirement already satisfied: asyncio<4.0.0,>=3.4.3 in /usr/local/lib/python3.9/dist-packages (from semantic-kernel==0.2.3.dev0) (3.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (2022.12.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.2.3.dev0) (1.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import semantic_kernel as sk\n",
        "from semantic_kernel.ai.open_ai import AzureTextCompletion, OpenAITextCompletion"
      ],
      "metadata": {
        "id": "Idj_UBuomgTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Instantiating the kernel"
      ],
      "metadata": {
        "id": "0HsRREPxmmU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple instance\n",
        "kernel_1 = sk.Kernel()"
      ],
      "metadata": {
        "id": "avxaJ5U-mkbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel.config.add_text_backend(               # We are adding a text backend\n",
        "    \"OpenAI_davinci\",                         # The alias we can use in prompt templates' config.json\n",
        "    OpenAITextCompletion(\n",
        "        \"text-davinci-003\",                   # OpenAI Model Name\n",
        "        \"sk-.........\",          # OpenAI API key\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wiZkhAXmoHk",
        "outputId": "c9977356-81e5-44b0-e6f0-b9dd14505377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<semantic_kernel.kernel_config.KernelConfig at 0x7f8b09bb5190>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skills_directory = \"/content/sample_data/\"\n",
        "\n",
        "funFunctions = kernel.import_semantic_skill_from_directory(skills_directory, \"FunSkill\")\n",
        "\n",
        "jokeFunction = funFunctions[\"Joke\"]"
      ],
      "metadata": {
        "id": "EFoskERCmz4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = jokeFunction(\"the results given by chatGPT\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beYX3EpBn4r0",
        "outputId": "8e3a350f-a9cd-4390-9931-3b646354e836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Q: What did the chatbot say when asked for the results?\n",
            "\n",
            "A: \"I'm sorry, I'm not a fortune teller. But I can tell you that the results are looking good!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using semantic kernel for Text summarization"
      ],
      "metadata": {
        "id": "YuIVzmKxqoXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"{{$input}}\n",
        "Summarize the content above.\n",
        "\"\"\"\n",
        "\n",
        "summarize = kernel.create_semantic_function(prompt, max_tokens=2000, temperature=0.2, top_p=0.5)"
      ],
      "metadata": {
        "id": "fQUH9JSNoYgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"\"\"\n",
        "Kumari Kandam is a mythical continent, believed to be lost with an ancient Tamil civilization, supposedly located south of present-day India in the Indian Ocean. Alternative names and spellings include Kumarikkandam and Kumari Nadu.\n",
        "\n",
        "In the 19th century, some European and American scholars speculated the existence of a submerged continent called Lemuria to explain geological and other similarities between Africa, Australia, the Indian subcontinent and Madagascar. A section of Tamil revivalists adapted this theory, connecting it to the Pandyan legends of lands lost to the ocean, as described in ancient Tamil and Sanskrit literature. According to these writers, an ancient Tamil civilisation existed on Lemuria, before it was lost to the sea in a catastrophe.\n",
        "\n",
        "In the 20th century, the Tamil writers started using the name Kumari Kandam to describe this submerged continent. Although the Lemuria theory was later rendered obsolete by the continental drift (plate tectonics) theory, the concept remained popular among Tamil revivalists of the 20th century. According to them, Kumari Kandam was the place where the first two Tamil literary academies (sangams) were organised during the Pandyan reign. They claimed Kumari Kandam as the cradle of civilisation to prove the antiquity of the Tamil language and culture.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3SW-36Pho6eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = summarize(input_text)\n",
        "\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd-xVpHlpQqh",
        "outputId": "b546a434-5a3d-4d42-8c1e-2db209ffa281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Kumari Kandam is a mythical lost continent believed to be located south of present-day India in the Indian Ocean. It was popularized by Tamil revivalists in the 20th century, who claimed it was the place where the first two Tamil literary academies (sangams) were organised during the Pandyan reign. This was based on the Lemuria theory, which was later rendered obsolete by the continental drift (plate tectonics) theory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sk_prompt = \"\"\"\n",
        "ChatBot can have a conversation with you about any topic.\n",
        "It can give explicit instructions or say 'I don't know' if it does not have an answer.\n",
        "\n",
        "{{$history}}\n",
        "User: {{$user_input}}\n",
        "ChatBot: \"\"\""
      ],
      "metadata": {
        "id": "jrNfsDaMpS25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating a chatbot with the semantic kernel function"
      ],
      "metadata": {
        "id": "tD22HjIlqiL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_function = kernel.create_semantic_function(sk_prompt, \"ChatBot\", max_tokens=2000, temperature=0.7, top_p=0.5)"
      ],
      "metadata": {
        "id": "TUPCe49qpbh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = sk.ContextVariables()\n",
        "context[\"history\"] = \"\""
      ],
      "metadata": {
        "id": "mxZA4XFHpeiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context[\"user_input\"] = \"Hi, I'm looking a nice city to live within the bay area\"\n",
        "bot_answer = await chat_function.invoke_with_vars_async(input=context)\n",
        "print(bot_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3pyf8W9ppI7",
        "outputId": "42adda46-52ed-4e4a-826d-c1fefe4d315d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hi there! What type of city are you looking for? Do you want a big city with lots of amenities or a smaller, more rural area?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context[\"history\"] += f\"\\nUser: {context['user_input']}\\nChatBot: {bot_answer}\\n\"\n",
        "print(context[\"history\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5M3hUTbpgyc",
        "outputId": "2d9c30af-92d8-497f-c22b-d582b194390a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User: Hi, I'm looking a nice city to live within the bay area\n",
            "ChatBot:  Hi there! What type of city are you looking for? Do you want a big city with lots of amenities or a smaller, more rural area?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context[\"history\"] += f\"\\nUser: {context['user_input']}\\nChatBot: {bot_answer}\\n\"\n",
        "print(context[\"history\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT328NgKpjOv",
        "outputId": "f1413c09-5496-48ce-ff41-5cb913ccc6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User: Hi, I'm looking a nice city to live within the bay area\n",
            "ChatBot:  Hi there! What type of city are you looking for? Do you want a big city with lots of amenities or a smaller, more rural area?\n",
            "\n",
            "User: Hi, I'm looking a nice city to live within the bay area\n",
            "ChatBot:  Hi there! What type of city are you looking for? Do you want a big city with lots of amenities or a smaller, more rural area?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def chat(input_text: str) -> None:\n",
        "    # Save new message in the context variables\n",
        "    print(f\"User: {input_text}\")\n",
        "    context[\"user_input\"] = input_text\n",
        "\n",
        "    # Process the user message and get an answer\n",
        "    answer = await chat_function.invoke_with_vars_async(context)\n",
        "\n",
        "    # Show the response\n",
        "    print(f\"ChatBot: {answer}\")\n",
        "\n",
        "    # Append the new interaction to the chat history\n",
        "    context[\"history\"] += f\"\\nUser: {input_text}\\nChatBot: {answer}\\n\""
      ],
      "metadata": {
        "id": "ui2arzj9puGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await chat(\"I would like a mix of both city and rural, I want my house to be in a quite community with greenery, but should be accessible to city supermartkets and offices\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4xbL4dGp96x",
        "outputId": "1caa95de-57c2-47fc-e88e-2f359b5ae584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: I would like a mix of both city and rural, I want my house to be in a quite community with greenery, but should be accessible to city supermartkets and offices\n",
            "ChatBot:  That sounds like a great idea! There are many cities in the Bay Area that offer a mix of city and rural living. Some of the most popular cities include San Francisco, Oakland, Berkeley, and Palo Alto. Each of these cities has its own unique charm and amenities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await chat(\"nice, what about the cost of living in these places\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYnv_8DAp_5e",
        "outputId": "d86d430c-ab69-4d55-e983-77d50fa92ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: nice, what about the cost of living in these places\n",
            "ChatBot:  The cost of living in the Bay Area can vary greatly depending on the city and neighborhood. Generally speaking, San Francisco and Palo Alto tend to be more expensive than Oakland and Berkeley. However, there are many affordable neighborhoods in each city that offer a great quality of life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await chat(\"what do you think of cities like fremont and sanjose\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtCCtt9VqCnH",
        "outputId": "1b7cbb0d-f103-4d78-e9ce-67304cc906c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: what do you think of cities like fremont and sanjose\n",
            "ChatBot:  Fremont and San Jose are both great cities in the Bay Area. Fremont is known for its diverse population and great schools, while San Jose is a vibrant city with a thriving tech industry. Both cities offer plenty of amenities and a great quality of life.\n"
          ]
        }
      ]
    }
  ]
}