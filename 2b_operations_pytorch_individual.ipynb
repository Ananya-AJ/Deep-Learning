{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2pojVdz+X6hE0dEFK/zEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananya-AJ/Deep-Learning/blob/main/2b_operations_pytorch_individual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zt46viOWb6eo"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar vector multiplication\n",
        "\n",
        "a = torch.rand(1)\n",
        "b = torch.rand(8, 3)\n",
        "mult = torch.einsum('i, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlr6_QCDcDQb",
        "outputId": "22e714e0-3e45-465e-cde1-8eaa930222e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9527])\n",
            "tensor([[0.9159, 0.5157, 0.5155],\n",
            "        [0.0795, 0.0986, 0.4750],\n",
            "        [0.7315, 0.0623, 0.7837],\n",
            "        [0.1413, 0.4651, 0.4515],\n",
            "        [0.7715, 0.9578, 0.0246],\n",
            "        [0.7536, 0.7605, 0.0524],\n",
            "        [0.8444, 0.9581, 0.2070],\n",
            "        [0.9302, 0.8836, 0.7917]])\n",
            "tensor([[0.8725, 0.4913, 0.4911],\n",
            "        [0.0757, 0.0940, 0.4525],\n",
            "        [0.6969, 0.0594, 0.7466],\n",
            "        [0.1346, 0.4430, 0.4301],\n",
            "        [0.7350, 0.9125, 0.0235],\n",
            "        [0.7179, 0.7245, 0.0500],\n",
            "        [0.8044, 0.9128, 0.1972],\n",
            "        [0.8862, 0.8418, 0.7542]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector vector multiplication\n",
        "\n",
        "a = torch.rand(3, 4)\n",
        "b = torch.rand(4, 6)\n",
        "mult = torch.einsum('ij, jk -> ik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83lCcUyJcJ7N",
        "outputId": "2a1a4d4a-dd30-4113-de4e-c709ca54b0b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2097, 0.5419, 0.4652, 0.7254],\n",
            "        [0.0995, 0.3792, 0.7318, 0.1850],\n",
            "        [0.3614, 0.4519, 0.0195, 0.9595]])\n",
            "tensor([[0.1836, 0.3458, 0.2365, 0.6283, 0.9129, 0.1729],\n",
            "        [0.6768, 0.4992, 0.4833, 0.6024, 0.7941, 0.7571],\n",
            "        [0.2811, 0.5799, 0.2425, 0.8327, 0.6434, 0.1461],\n",
            "        [0.7048, 0.6511, 0.5994, 0.2550, 0.3839, 0.4551]])\n",
            "tensor([[1.0472, 1.0851, 0.8591, 1.0305, 1.1995, 0.8446],\n",
            "        [0.6109, 0.7685, 0.4951, 0.9474, 0.9338, 0.4954],\n",
            "        [1.0539, 0.9866, 0.8837, 0.7602, 1.0696, 0.8442]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer product\n",
        "\n",
        "a = torch.arange(4)\n",
        "b = torch.arange(5, 6)  \n",
        "prod = torch.einsum('i,j -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP89Q_TfcHP3",
        "outputId": "dd07b03f-e2e4-4299-8c15-ff55cb682040"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n",
            "tensor([5])\n",
            "tensor([[ 0],\n",
            "        [ 5],\n",
            "        [10],\n",
            "        [15]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar dot product\n",
        "\n",
        "a = torch.arange(9).reshape(3, 3)\n",
        "b = torch.arange(6).reshape(3, 2)\n",
        "prod = torch.einsum('ij, jk ->', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7R-iiCDcTZw",
        "outputId": "26ef27b8-d1e5-4a1d-aa7e-f313f64feca7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5]])\n",
            "tensor(204)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hadamard product\n",
        "\n",
        "a = torch.arange(8).reshape(2, 4)\n",
        "b = torch.arange(4, 12).reshape(2, 4)\n",
        "prod = torch.einsum('ij, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbroC0oJcVsF",
        "outputId": "ac41ea5f-985e-4ac8-d34c-5a4a6c3fd5aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "tensor([[ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[ 0,  5, 12, 21],\n",
            "        [32, 45, 60, 77]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch matrix multiplication\n",
        "\n",
        "a = torch.randn(3, 3, 6)\n",
        "b = torch.randn(3, 6, 2)\n",
        "batch_mult = torch.einsum('bij, bjk -> bik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(batch_mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h51dGjkcYCZ",
        "outputId": "d19d7f9c-cf3a-4ea9-f41b-dac98ab63c3c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.4792,  0.4405, -0.8789, -1.5049, -0.3394,  0.9293],\n",
            "         [-1.1061, -1.4470,  0.2143, -0.7699,  0.9990, -1.4475],\n",
            "         [-1.7678,  0.2661,  1.5959,  0.4693, -1.0327,  1.8573]],\n",
            "\n",
            "        [[ 0.6898,  0.1513,  0.3559, -1.5186, -1.2020,  0.7653],\n",
            "         [ 0.1598, -1.0463,  0.5399,  0.2603,  0.0208,  0.2813],\n",
            "         [ 0.0309, -0.6352, -0.9038,  0.2339,  1.4732, -1.4333]],\n",
            "\n",
            "        [[-1.5101,  0.8978,  0.3703, -0.4329, -2.0541,  1.9545],\n",
            "         [-1.6846, -1.1632,  0.4950, -0.2574,  1.3567, -0.0393],\n",
            "         [ 0.7013, -0.5347, -1.0344, -1.4109, -1.6172,  0.3820]]])\n",
            "tensor([[[ 1.2306,  0.3978],\n",
            "         [ 0.4323, -0.1920],\n",
            "         [-1.0035, -0.6500],\n",
            "         [ 0.4711,  0.3029],\n",
            "         [-0.4294, -0.3311],\n",
            "         [ 1.4648,  0.7701]],\n",
            "\n",
            "        [[ 0.1334, -0.3789],\n",
            "         [-0.3706,  0.7323],\n",
            "         [-0.1679, -0.3407],\n",
            "         [ 0.6593,  0.7570],\n",
            "         [-0.1165, -0.3981],\n",
            "         [ 0.2081,  1.0039]],\n",
            "\n",
            "        [[ 0.3971,  0.0693],\n",
            "         [ 0.5953, -1.9211],\n",
            "         [-0.0640,  0.7866],\n",
            "         [ 0.9188,  0.8773],\n",
            "         [ 0.1413, -1.1845],\n",
            "         [ 0.2269,  1.4456]]])\n",
            "tensor([[[ 1.2807,  0.6683],\n",
            "         [-5.1138, -1.9803],\n",
            "         [-0.2769,  0.1227]],\n",
            "\n",
            "        [[-0.7257, -0.1746],\n",
            "         [ 0.5462, -0.5394],\n",
            "         [ 0.0755, -2.0173]],\n",
            "\n",
            "        [[-0.3334,  3.3407],\n",
            "         [-1.4467,  0.6175],\n",
            "         [-1.4118,  1.4924]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor reduction\n",
        "\n",
        "a = torch.randn(2, 3, 5, 7)\n",
        "b = torch.randn(4, 1, 3, 11, 5)\n",
        "reduction = torch.einsum('pqrs, tuqvr -> pstuv', [a, b])\n",
        "print(a.shape, b.shape, reduction.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEeVTGWUcaUN",
        "outputId": "1b2e4566-ff96-45ed-e477-3061964311f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 5, 7]) torch.Size([4, 1, 3, 11, 5]) torch.Size([2, 7, 4, 1, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose\n",
        "\n",
        "a = torch.arange(8).reshape(2, 4)\n",
        "transpose = torch.einsum('ij -> ji', [a])\n",
        "print(a)\n",
        "print(transpose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiplNRXbccmy",
        "outputId": "31e6b7c8-c54a-4951-b114-c3360244af8a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "tensor([[0, 4],\n",
            "        [1, 5],\n",
            "        [2, 6],\n",
            "        [3, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bilinear transformation\n",
        "\n",
        "a = torch.randn(2, 3)\n",
        "b = torch.randn(3, 3, 4)\n",
        "c = torch.randn(2, 4)\n",
        "bilinear = torch.einsum('ik, jkl, il -> ij', [a, b, c])\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(bilinear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJGT23pWce0N",
        "outputId": "93288572-1f8e-4f66-aedd-7dea3de8eb10"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.4101,  1.0852, -0.4636],\n",
            "        [ 0.1006, -0.5854, -2.7060]])\n",
            "tensor([[[ 0.3137, -0.4361, -0.3223, -0.3241],\n",
            "         [-0.3332,  0.0225,  0.7285,  1.7542],\n",
            "         [ 1.6624, -0.3904,  1.2754,  0.2033]],\n",
            "\n",
            "        [[-1.6571, -0.4836,  0.1261,  1.7263],\n",
            "         [-0.1359, -0.4000,  0.0607,  1.1899],\n",
            "         [ 1.9795,  0.7114, -1.0291,  1.0837]],\n",
            "\n",
            "        [[-1.1518, -0.1152,  0.9695,  0.2678],\n",
            "         [-0.8789,  1.2201,  0.0176,  0.3097],\n",
            "         [-1.0023, -0.8663,  0.5402, -0.3465]]])\n",
            "tensor([[ 1.3945,  0.6184, -0.5007, -0.8351],\n",
            "        [-0.1520,  0.5575,  1.5790, -0.3589]])\n",
            "tensor([[-3.9085,  2.9139,  3.4512],\n",
            "        [-4.3896,  5.4588, -2.0223]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention\n",
        "\n",
        "def random_tensors(shape, num=1, requires_grad=False):\n",
        "  tensors = [torch.randn(shape, requires_grad=requires_grad) for i in range(0, num)]\n",
        "  return tensors[0] if num == 1 else tensors\n",
        "\n",
        "# Parameters\n",
        "# [hidden_dimension]\n",
        "bM, br, w = random_tensors([7], num=3, requires_grad=True)\n",
        "# [hidden_dimension x hidden_dimension]\n",
        "WY, Wh, Wr, Wt = random_tensors([7, 7], num=4, requires_grad=True)\n",
        "\n",
        "def attention(Y, ht, rt1):\n",
        "  # [batch_size x hidden_dimension] \n",
        "  tmp = torch.einsum('ik, kl -> il', [ht, Wh]) + torch.einsum('ik, kl -> il', [rt1, Wr])\n",
        "\n",
        "  Mt = torch.tanh(torch.einsum('ijk, kl -> ijl', [Y, WY]) + tmp.unsqueeze(1).expand_as(Y) + bM)\n",
        "  \n",
        "  # [batch_size x sequence_length]\n",
        "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w])) \n",
        "  \n",
        "  # [batch_size x hidden_dimension]\n",
        "  rt = torch.einsum('ijk, ij -> ik', [Y, at]) + torch.tanh(torch.einsum('ij, jk -> ik', [rt1, Wt]) + br)\n",
        "  \n",
        "  return rt, at\n",
        "\n",
        "# Inputs - [batch_size x sequence_length x hidden_dimension]\n",
        "Y = torch.randn(3,5,7)\n",
        "# [batch_size x hidden_dimension]\n",
        "ht, rt1 = random_tensors([3, 7], num=2)\n",
        "\n",
        "rt, at = attention(Y, ht, rt1)\n",
        "\n",
        "print(at)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DApSqjlucheO",
        "outputId": "e567c68e-2342-4a86-95a9-73efe3d79ab9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5012, 0.2671, 0.1465, 0.0302, 0.0550],\n",
            "        [0.5457, 0.0989, 0.0013, 0.0011, 0.3529],\n",
            "        [0.3610, 0.0948, 0.1997, 0.1840, 0.1605]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-0f495568e4dc>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treeqn\n",
        "\n",
        "def transition(zl):\n",
        "  # [batch_size x num_actions x hidden_dimension]\n",
        "  return zl.unsqueeze(1) + torch.tanh(torch.einsum('bk, aki -> bai', [zl, W]) + b)\n",
        "\n",
        "# Inputs - [batch_size x hidden_dimension]\n",
        "zl = torch.randn(2, 3)\n",
        "# Parameters - [num_actions x hidden_dimension]\n",
        "b = torch.randn(5, 3)\n",
        "# Actions - [num_actions x hidden_dimension x hidden_dimension]\n",
        "W = torch.randn(5, 3, 3)\n",
        "\n",
        "transition(zl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsbI1QdtclmU",
        "outputId": "faf3b60b-bab7-480e-91b3-8b4c4d1ef418"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.5253,  0.3540,  0.1424],\n",
              "         [-2.3261,  0.4054, -0.3410],\n",
              "         [-0.4074,  0.5071,  0.1663],\n",
              "         [-1.2789,  0.6472,  0.0891],\n",
              "         [-2.2515,  0.6404, -1.0033]],\n",
              "\n",
              "        [[-0.6477, -0.8759, -0.3058],\n",
              "         [-0.6614, -2.5155, -0.0969],\n",
              "         [-0.6276, -1.9070,  0.2905],\n",
              "         [ 1.0452, -0.6064, -0.5417],\n",
              "         [ 0.1474, -2.3005, -1.5779]]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}